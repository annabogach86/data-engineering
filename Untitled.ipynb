{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ac35ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import requests as req\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2db7af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_main = \"https://vetapteka45.ru\"\n",
    "url_korm = f\"{url_main}/catalog/korma/\"\n",
    "suburl_korm_suh = \"suhoj-korm/\"\n",
    "suburl_korm_vl= \"vlazhnyj-korm-konservy/\"\n",
    "suburl_korm_lak = \"lakomstva/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c27948f",
   "metadata": {},
   "outputs": [],
   "source": [
    "suburl_korm = [suburl_korm_suh, suburl_korm_vl, suburl_korm_lak]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efe5e946",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_antib = f\"{url_main}/catalog/antibiotiki/\"\n",
    "suburl_antib_inj = \"inekcionnye/\"\n",
    "suburl_antib = [suburl_antib_inj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1d55532",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_numb = 5\n",
    "file_path = 'tests/' + str(z_numb)\n",
    "filename = file_path + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42752ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_out_filename = f\"{file_path}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27eda01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bld_name_freq = {}\n",
    "new_info = []\n",
    "pl = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dedf00aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "antib_name_freq = {}\n",
    "antib_info = []\n",
    "antib_pl = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0101e432",
   "metadata": {},
   "outputs": [],
   "source": [
    "antib_country_freq = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5b32912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_dict(m, fdict):\n",
    "    m = m.lower()\n",
    "    if m in fdict:\n",
    "        fdict[m] += 1\n",
    "    else:\n",
    "        fdict.setdefault(m, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90cd81bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html_file(url, purl):\n",
    "    url_get = url + purl\n",
    "    print(\"request to : \", url_get)\n",
    "    resp = req.get(url_get)\n",
    "    html_filename = f\"dl/{purl.split('/')[-2]}.html\"\n",
    "    # print(html_filename)\n",
    "    if resp.status_code != 200:\n",
    "        with open(f\"{file_path}/{html_filename}\", mode=\"r\") as html_f:\n",
    "            resp = html_f.readlines()\n",
    "        return \"\".join(resp)\n",
    "    else:\n",
    "        dl_dir = file_path + \"/dl\"\n",
    "        if not os.path.exists(dl_dir):\n",
    "            os.mkdir(dl_dir)\n",
    "        if not os.path.exists(html_filename):\n",
    "            with open(f\"{file_path}/{html_filename}\", mode = \"w\") as html_f:\n",
    "                html_f.write(resp.text)\n",
    "    return resp.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f9bf512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request to :  https://vetapteka45.ru/catalog/antibiotiki/inekcionnye/\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Системе не удается найти указанный путь: 'tests/5/dl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\73B5~1\\AppData\\Local\\Temp/ipykernel_15316/1900048377.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcurl\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msuburl_antib\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_html_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_antib\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mcontent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"div\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"class\"\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;34m\"catalog_item col-12 col-sm-6 col-md-6 col-lg-3\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\73B5~1\\AppData\\Local\\Temp/ipykernel_15316/3082898489.py\u001b[0m in \u001b[0;36mget_html_file\u001b[1;34m(url, purl)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mdl_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/dl\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdl_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdl_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{file_path}/{html_filename}\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"w\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mhtml_f\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Системе не удается найти указанный путь: 'tests/5/dl'"
     ]
    }
   ],
   "source": [
    "for curl in suburl_antib:\n",
    "    resp = get_html_file(url_antib, curl)\n",
    "    soup = BeautifulSoup(resp, 'html.parser')\n",
    "    content = soup.find_all(\"div\", {\"class\" : \"catalog_item col-12 col-sm-6 col-md-6 col-lg-3\"})\n",
    "    for cv in content:\n",
    "        item = {}\n",
    "        link = cv.find('a', {\"class\" : \"art\"})\n",
    "        href = link.get('href')\n",
    "        p_name = cv.find(\"p\", {\"class\" : \"name\"})\n",
    "        page = get_html_file(url_main, href)\n",
    "        item['url'] = href\n",
    "        item['name'] = p_name.text\n",
    "        ps = BeautifulSoup(page, 'html.parser')\n",
    "        discr = ps.find(\"div\", {\"class\" : \"col-12 col-md-7 product_page_description\"})\n",
    "        p_manuf = discr.find(\"p\", {\"class\" : \"manufacturer\"})\n",
    "        p_ishere = discr.find(\"p\", {\"class\" : \"is_here\"})\n",
    "        mname = \" \".join(p_manuf.text.split()[1:])\n",
    "        item['manufacturer'] = mname\n",
    "        add_to_dict(mname, antib_name_freq)       \n",
    "        count = 0\n",
    "        if p_ishere:\n",
    "            count = int(p_ishere.text.split()[1].replace(\".\", \"\"))\n",
    "        item['count'] = count\n",
    "        p_price = discr.find(\"span\", {\"class\" : \"price\"})\n",
    "        item['price'] = int(p_price.text.replace(\" \", \"\")[0:-1])\n",
    "        antib_pl.append(item['price'])\n",
    "        tab_content = ps.find(\"div\", {\"class\" : \"tab-content\"})\n",
    "        t_features = tab_content.find(\"div\", {\"class\" : \"features\"})\n",
    "        span_li = iter(t_features.find_all(\"span\"))\n",
    "        item['features'] = {}\n",
    "        item['features']['type'] = next(span_li).text\n",
    "        item['features']['country'] = next(span_li).text\n",
    "        add_to_dict(item['features']['country'], antib_country_freq)    \n",
    "        item['features']['weight'] = next(span_li).text        \n",
    "        f_count = 0\n",
    "        try:\n",
    "            f_count = int(next(span_li).text.replace(\".\", \"\"))\n",
    "        except:\n",
    "            pass            \n",
    "        item['features']['count'] = f_count\n",
    "        antib_info.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031c5f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfilename = \"antib_outfile.json\"\n",
    "json_out_filename_final = json_out_filename + \"final_\" + outfilename\n",
    "json_out_filename_sorted = json_out_filename + \"sorted_\" + outfilename\n",
    "json_out_filename_filter = json_out_filename + \"filter_\" + outfilename\n",
    "json_out_filename_freq = json_out_filename + \"freq_\" + outfilename\n",
    "json_out_filename_freq2 = json_out_filename + \"freq2_\" + outfilename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac5e95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Results by price\")\n",
    "print(f\"min {np.min(antib_pl)}\\nmax {np.max(antib_pl)}\\nmean {np.mean(antib_pl)}\\nstd {np.std(antib_pl)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35951442",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_out_filename_final, mode=\"w\") as f_json:\n",
    "    json.dump(antib_info, f_json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
